{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Homo LR Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "In this demo, we use the homo_logistic_regression(https://github.com/FederatedAI/FATE/tree/master/examples/federatedml-1.x-examples/homo_logistic_regression example. It is:\n",
        "* Homogeneous federated machine learning example, which both parties share same attributes but different samples;\n",
        "* Use breast cancer data original from Kaggle: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
        "* For easy to demo, both party we use the same FATE cluster: 10000. But the underlayer is the same, each side threat the collborated party go through the network to another party. \n",
        "\n",
        "Step 0. Prepare the libary to manage federated machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "import json\nimport time\nimport os\nimport requests\n\nimport fml_manager\nfrom fml_manager import *\n\nmanager \u003d fml_manager.FMLManager()"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Step 1. Upload the guest, host and test data. Because we use same cluster for this demo, we load all data in same NOTEBOOK. If we use another party for host, the host data should load in the NOTEBOOK of that party."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\u0027data\u0027: {\u0027board_url\u0027: \u0027http://fateboard:8080/index.html#/dashboard?job_id\u003d2020063006322784993833\u0026role\u003dlocal\u0026party_id\u003d0\u0027, \u0027job_dsl_path\u0027: \u0027/data/projects/fate/python/jobs/2020063006322784993833/job_dsl.json\u0027, \u0027job_runtime_conf_path\u0027: \u0027/data/projects/fate/python/jobs/2020063006322784993833/job_runtime_conf.json\u0027, \u0027logs_directory\u0027: \u0027/data/projects/fate/python/logs/2020063006322784993833\u0027, \u0027namespace\u0027: \u0027homo_breast_guest\u0027, \u0027table_name\u0027: \u0027homo_breast_guest\u0027}, \u0027jobId\u0027: \u00272020063006322784993833\u0027, \u0027retcode\u0027: 0, \u0027retmsg\u0027: \u0027success\u0027}\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: success\n",
            "Status: success\n",
            "Status: success\n",
            "success,success,success\n",
            "Success\n"
          ]
        }
      ],
      "source": [
        "response \u003d manager.load_data(url\u003d\u0027./data/breast_homo_guest.csv\u0027, namespace\u003d\u0027homo_breast_guest\u0027, table_name\u003d\u0027homo_breast_guest\u0027, work_mode\u003d1, head\u003d1, partition\u003d10)\n",
        "output \u003d json.loads(response.content)\n",
        "print(output)\n",
        "guest_job_id \u003d output[\"jobId\"]\n",
        "guest_query_condition \u003d {\n",
        "    \u0027job_id\u0027:guest_job_id\n",
        "}\n",
        "response \u003d manager.load_data(url\u003d\u0027./data/breast_homo_host.csv\u0027, namespace\u003d\u0027homo_breast_host\u0027, table_name\u003d\u0027homo_breast_host\u0027, work_mode\u003d1, head\u003d1, partition\u003d10)\n",
        "output \u003d json.loads(response.content)\n",
        "host_job_id \u003d output[\"jobId\"]\n",
        "host_query_condition \u003d {\n",
        "    \u0027job_id\u0027:host_job_id\n",
        "}\n",
        "response \u003d manager.load_data(url\u003d\u0027./data/breast_homo_test.csv\u0027, namespace\u003d\u0027homo_breast_test\u0027, table_name\u003d\u0027homo_breast_test\u0027, work_mode\u003d1, head\u003d1, partition\u003d10)\n",
        "output \u003d json.loads(response.content)\n",
        "test_job_id \u003d output[\"jobId\"]\n",
        "test_query_condition \u003d {\n",
        "    \u0027job_id\u0027:test_job_id\n",
        "}\n",
        "\n",
        "\n",
        "manager.query_job_status(guest_query_condition)\n",
        "manager.query_job_status(host_query_condition)\n",
        "manager.query_job_status(host_query_condition)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Step 2. Create the steps DSL and configuration of each step for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "# dsl\ndata_io \u003d ComponentBuilder()\\\n    .with_name(\u0027dataio_0\u0027)\\\n    .with_module(\u0027DataIO\u0027)\\\n    .with_input_data(\u0027arg.train_data\u0027)\\\n    .with_output_data(\u0027train\u0027)\\\n    .with_output_model(\u0027dataio\u0027).build()\n        \n\nhomo_lr \u003d ComponentBuilder()\\\n    .with_name(\u0027homo_lr_0\u0027)\\\n    .with_module(\u0027HomoLR\u0027)\\\n    .with_input_train_data(\u0027dataio_0.train\u0027)\\\n    .with_output_data(\u0027train\u0027)\\\n    .with_output_model(\u0027homolr\u0027).build()\n\nevaluation \u003d ComponentBuilder()\\\n    .with_name(\u0027evaluation_0\u0027)\\\n    .with_module(\u0027Evaluation\u0027)\\\n    .with_input_data(\u0027homo_lr_0.train\u0027)\\\n    .with_output_data(\u0027evaluate\u0027).build()\n\ndsl \u003d PiplineBuilder()\\\n    .with_components(\n        data_io, \n        hetero_lr, \n        evaluation).build()\n\n# Configuration\ninitiator \u003d InitiatorBuilder()\\\n    .with_role(\"guest\")\\\n    .with_party_id(10000).build()\n\n\njob_parameters \u003d JobParametersBuilder()\\\n    .with_work_mode(1).build()\n\nrole \u003d RoleBuilder()\\\n    .with_guest(10000)\\\n    .with_host(10000)\\\n    .with_arbiter(10000).build()\n\neval_config \u003d {\n       \"need_run\": [False]\n }\n\nrole_parameters \u003d RoleParametersBuilder()\\\n    .with_guest_train_data(namespaces\u003d[\u0027homo_breast_guest\u0027], names\u003d[\u0027homo_breast_guest\u0027])\\\n    .with_host_train_data(namespaces\u003d[\u0027homo_breast_host\u0027], names\u003d[\u0027homo_breast_host\u0027])\\\n    .with_host_module_config(modules\u003d[\u0027evalution_0\u0027], configs\u003d[eval_config]).build()\n\n\nhomo_lr_params \u003d {\n            \"penalty\": \"L2\",\n            \"optimizer\": \"sgd\",\n            \"eps\": 1e-5,\n            \"alpha\": 0.01,\n            \"max_iter\": 10,\n            \"converge_func\": \"diff\",\n            \"batch_size\": 500,\n            \"learning_rate\": 0.15,\n            \"decay\": 1,\n            \"decay_sqrt\": True,\n            \"init_param\": {\n                \"init_method\": \"zeros\"\n            },\n            \"encrypt_param\": {\n                \"method\": \"Paillier\"\n            },\n            \"cv_param\": {\n                \"n_splits\": 4,\n                \"shuffle\": True,\n                \"random_seed\": 33,\n                \"need_cv\": False\n            }\n        }\ndotaio_config \u003d {\n            \"with_label\": True,\n            \"label_name\": \"y\",\n            \"label_type\": \"int\",\n            \"output_format\": \"dense\"\n        },\n\nalgorithm_parameters \u003d AlgorithmParametersBuilder()\\\n    .with_module_config(modules\u003d[\u0027homo_lr_0\u0027, \u0027dataio_0\u0027], configs\u003d[homo_lr_params, dotaio_config]).build()\n\nconfig \u003d ConfigBuilder()\\\n    .with_initiator(initiator)\\\n    .with_job_parameters(job_parameters)\\\n    .with_role(role)\\\n    .with_role_parameters(role_parameters)\\\n    .with_algorithm_parameters(algorithm_parameters).build()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "Step 3. Submit the training job to GUEST cluster. And it will notify and bring up the HOST cluster and train together. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success!\n",
            "{\n",
            "    \"data\": {\n",
            "        \"board_url\": \"http://fateboard:8080/index.html#/dashboard?job_id\u003d2020063006362564981036\u0026role\u003dguest\u0026party_id\u003d9999\",\n",
            "        \"job_dsl_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_dsl.json\",\n",
            "        \"job_runtime_conf_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_runtime_conf.json\",\n",
            "        \"logs_directory\": \"/data/projects/fate/python/logs/2020063006362564981036\",\n",
            "        \"model_info\": {\n",
            "            \"model_id\": \"arbiter-9999#guest-9999#host-9999#model\",\n",
            "            \"model_version\": \"2020063006362564981036\"\n",
            "        }\n",
            "    },\n",
            "    \"jobId\": \"2020063006362564981036\",\n",
            "    \"retcode\": 0,\n",
            "    \"retmsg\": \"success\"\n",
            "}\n",
            "Status: waiting\n",
            "Status: waiting\n",
            "Status: waiting\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: running\n",
            "Status: success\n",
            "Success\n",
            "Success!\n",
            "{\n",
            "    \"data\": {\n",
            "        \"board_url\": \"http://fateboard:8080/index.html#/dashboard?job_id\u003d2020063006362564981036\u0026role\u003dguest\u0026party_id\u003d9999\",\n",
            "        \"job_dsl_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_dsl.json\",\n",
            "        \"job_runtime_conf_path\": \"/data/projects/fate/python/jobs/2020063006362564981036/job_runtime_conf.json\",\n",
            "        \"logs_directory\": \"/data/projects/fate/python/logs/2020063006362564981036\",\n",
            "        \"model_info\": {\n",
            "            \"model_id\": \"arbiter-9999#guest-9999#host-9999#model\",\n",
            "            \"model_version\": \"2020063006362564981036\"\n",
            "        }\n",
            "    },\n",
            "    \"jobId\": \"2020063006362564981036\",\n",
            "    \"retcode\": 0,\n",
            "    \"retmsg\": \"success\"\n",
            "}\n"
          ]
        }
      ],
      "source": "response \u003d manager.submit_job(dsl.to_dict(),config.to_dict())\nmanager.prettify(response, verbose\u003dTrue)\nstdout \u003d json.loads(response.content)\njobId \u003d stdout[\"jobId\"]\nquery_condition \u003d {\n    \u0027job_id\u0027:jobId\n}\n\nmodel_id, model_version \u003d \u0027\u0027, \u0027\u0027\nmanager.query_job_status(query_condition)\n\nmanager.prettify(response, verbose\u003dTrue)\noutput \u003d json.loads(response.content)\nmodel_id, model_version \u003d output[\"data\"][\"model_info\"][\"model_id\"], output[\"data\"][\"model_info\"][\"model_version\"]"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\u0027metadata\u0027: \u0027CgJMMhHxaOOItfjkPhl7FK5H4XqEPyIDc2dkMPQDOTMzMzMzM8M/QApKBGRpZmZQAlgB\u0027, \u0027parameters\u0027: \u0027CAoSUP4QBQQ+79o/Y+ScSvKa1j+RTreM/XfUPyk/T2KsNtM/ik0jT2po0j+lMOUXo9zRPwWjqz1MetE/3VWUfhkz0T8KB2etSv7QP5ymdO1A1tA/Ig0KAngwEbJDSoWA/sG/Ig0KAngxEcob/dudLr6/Ig0KAngyEWYZ+hcRpMG/Ig0KAngzEfWv/7Rc+r+/Ig0KAng0EbDD/W9RW7m/Ig0KAng1Eb6OMlppJri/Ig0KAng2EbIEbULVqru/Ig0KAng3ERQQVXbn+MG/Ig0KAng4EW6/Nt4yu7W/Ig0KAng5EQJZbnGtrKW/Ig4KA3gxMBEsGFvBSI3AvyIOCgN4MTERZZM+KKAGur8iDgoDeDEyEdGPglYzgMC/Ig4KA3gxMxHa0QRjolK+vyIOCgN4MTQR9tqVWW+Fr78iDgoDeDE1ETwimmbYbLO/Ig4KA3gyMBG7wwtUoXG0vyIOCgN4MTYRIGmQvHuRur8iDgoDeDIxEdqP/oYJfnY/Ig4KA3gxNxFSVtQreM/AvyIOCgN4MjIRzQmY7no3sr8iDgoDeDIzEcwFGjerVbK/Ig4KA3gxOBHDXhlmJQ2rvyIOCgN4MjQRoPtqyzc7iD8iDgoDeDE5EXOSYAuFHaM/Ig4KA3gyNRGNsnK5wSqBvyIOCgN4MjYRna/Rsrf0Gj8iDgoDeDI3EUcfkMZaT6a/Ig4KA3gyOBHXUPahnWidPyIOCgN4MjkRXdrDc3/ooD8pCAy8iYha4T8yAngwMgJ4MTICeDIyAngzMgJ4NDICeDUyAng2MgJ4NzICeDgyAng5MgN4MTAyA3gxMTIDeDEyMgN4MTMyA3gxNDIDeDE1MgN4MTYyA3gxNzIDeDE4MgN4MTkyA3gyMDIDeDIxMgN4MjIyA3gyMzIDeDI0MgN4MjUyA3gyNjIDeDI3MgN4MjgyA3gyOQ\u003d\u003d\u0027}\n"
          ]
        }
      ],
      "source": [
        "response \u003d manager.model_output(\u0027guest\u0027, \u002710000\u0027, model_id, model_version, \u0027homo_lr_0.homolr:HomoLogisticRegression\u0027)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "And we can try offline prediction feature. Prediction also need both parts participant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"data\":{\"board_url\":\"http://fateboard:8080/index.html#/dashboard?job_id\u003d202005070653465729886\u0026role\u003dguest\u0026party_id\u003d10000\",\"job_dsl_path\":\"/data/projects/fate/python/jobs/202005070653465729886/job_dsl.json\",\"job_runtime_conf_path\":\"/data/projects/fate/python/jobs/202005070653465729886/job_runtime_conf.json\",\"logs_directory\":\"/data/projects/fate/python/logs/202005070653465729886\",\"model_info\":{\"model_id\":\"arbiter-10000#guest-10000#host-10000#model\",\"model_version\":\"202005070651022620445\"}},\"jobId\":\"202005070653465729886\",\"retcode\":0,\"retmsg\":\"success\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "is_vertical \u003d False\n",
        "initiator_party_role \u003d \u0027guest\u0027\n",
        "initiator_party_id \u003d \u002710000\u0027\n",
        "work_mode \u003d 1\n",
        "federated_roles \u003d {\n",
        "        \u0027guest\u0027: [10000],\n",
        "        \u0027host\u0027: [10000],\n",
        "        \u0027arbiter\u0027: [10000]\n",
        "}\n",
        "guest_data_name \u003d \u0027homo_breast_test\u0027\n",
        "guest_data_namespace \u003d \u0027homo_breast_test\u0027\n",
        "host_data_name \u003d \u0027homo_breast_test\u0027\n",
        "host_data_namespace \u003d \u0027homo_breast_test\u0027\n",
        "\n",
        "response \u003d manager.offline_predict_on_dataset(is_vertical, initiator_party_role, initiator_party_id, work_mode, model_id, model_version, federated_roles, guest_data_name, guest_data_namespace, host_data_name, host_data_namespace)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "The result can be checked in FATE-Board."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}